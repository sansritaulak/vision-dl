{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b401d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import autocast\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchmetrics.classification import MulticlassCalibrationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44035764",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"model_path\": \"C:/cifar-week3/artifacts/day3_resnet18-full-unfreeze.pth\",\n",
    "    \"data_root\": \"./data\",\n",
    "    \"artifacts_dir\": \"artifacts\",\n",
    "    \"batch_size\": 64,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"num_classes\": 10,\n",
    "    \"num_misclassified\": 20,\n",
    "    \"num_gradcam\": 20,\n",
    "    \"noise_std\": 0.1,\n",
    "    \"ece_bins\": 15,\n",
    "}\n",
    "\n",
    "CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "NORMALIZE_MEAN = [0.4914, 0.4822, 0.4465]\n",
    "NORMALIZE_STD = [0.2470, 0.2430, 0.2610]\n",
    "\n",
    "print(\"Imports complete\")\n",
    "print(f\"Using device: {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "wandb.init(\n",
    "    project=\"cifar10-week3\",\n",
    "    name=\"day4-diagnostics-gradcam-calibration\",\n",
    "    group=\"Day4_Diagnostics_GradCAM_Calibration\",\n",
    "    config={\n",
    "        \"model\": \"ResNet18 (fine-tuned)\",\n",
    "        \"task\": \"Diagnostics + Attribution + Calibration\",\n",
    "        **CONFIG\n",
    "    }\n",
    ")\n",
    "print(\"W&B initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(CONFIG[\"device\"])\n",
    "\n",
    "if not os.path.exists(CONFIG[\"model_path\"]):\n",
    "    raise FileNotFoundError(f\"Model not found at {CONFIG['model_path']}\")\n",
    "\n",
    "model = timm.create_model(\"resnet18\", pretrained=False, num_classes=CONFIG[\"num_classes\"])\n",
    "model.load_state_dict(torch.load(CONFIG[\"model_path\"], map_location=device))\n",
    "model.eval().to(device)\n",
    "print(\"Model loaded and ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=CONFIG[\"data_root\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Test dataset loaded: {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9e2ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_image(img_tensor):\n",
    "    \"\"\"Denormalize image tensor for visualization.\"\"\"\n",
    "    mean = torch.tensor(NORMALIZE_MEAN).view(3, 1, 1)\n",
    "    std = torch.tensor(NORMALIZE_STD).view(3, 1, 1)\n",
    "    img = img_tensor * std + mean\n",
    "    return torch.clamp(img, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finding top misclassified examples...\")\n",
    "misclassified = []\n",
    "device_type = \"cuda\" if device.type == \"cuda\" else \"cpu\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (img, label) in enumerate(test_loader):\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        \n",
    "        with autocast(device_type):\n",
    "            output = model(img)\n",
    "        \n",
    "        prob = F.softmax(output, dim=1)\n",
    "        confidence, pred = torch.max(prob, 1)\n",
    "        \n",
    "        if pred.item() != label.item():\n",
    "            misclassified.append({\n",
    "                \"index\": i,\n",
    "                \"true\": CLASSES[label.item()],\n",
    "                \"pred\": CLASSES[pred.item()],\n",
    "                \"confidence\": confidence.item(),\n",
    "                \"img\": img.cpu().squeeze(0)\n",
    "            })\n",
    "\n",
    "# Sort by confidence (descending) and take top 20\n",
    "misclassified = sorted(misclassified, key=lambda x: -x[\"confidence\"])[:CONFIG[\"num_misclassified\"]]\n",
    "print(f\"Found {len(misclassified)} misclassified examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ae86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{CONFIG['artifacts_dir']}/misclassified\", exist_ok=True)\n",
    "\n",
    "misclassified_table = wandb.Table(columns=[\"Image\", \"True\", \"Pred\", \"Confidence\"])\n",
    "\n",
    "for item in misclassified:\n",
    "    # Denormalize image\n",
    "    img = denormalize_image(item[\"img\"])\n",
    "    img_pil = transforms.ToPILImage()(img)\n",
    "    \n",
    "    path = f\"{CONFIG['artifacts_dir']}/misclassified/{item['index']}_{item['true']}_as_{item['pred']}.png\"\n",
    "    img_pil.save(path)\n",
    "    \n",
    "    misclassified_table.add_data(\n",
    "        wandb.Image(path),\n",
    "        item[\"true\"],\n",
    "        item[\"pred\"],\n",
    "        f\"{item['confidence']:.3f}\"\n",
    "    )\n",
    "\n",
    "wandb.log({\"Misclassified Top 20\": misclassified_table})\n",
    "print(f\"Logged {len(misclassified)} misclassified examples to W&B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a854369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if ANY gradients flow through your model\n",
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "test_input = torch.randn(1, 3, 32, 32, requires_grad=True).to(device)\n",
    "test_output = model(test_input)\n",
    "test_loss = test_output[0, 3]  # Pick one output\n",
    "test_loss.backward()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GRADIENT FLOW TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Input has gradient: {test_input.grad is not None}\")\n",
    "if test_input.grad is not None:\n",
    "    print(f\"Input gradient norm: {test_input.grad.norm().item():.6f}\")\n",
    "    print(\"✓ Gradients ARE flowing through the model\")\n",
    "else:\n",
    "    print(\"✗ Gradients are NOT flowing - model architecture issue!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a12892",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating Grad-CAM heatmaps...\")\n",
    "print(\"=\" * 60)\n",
    "print(\"DIAGNOSTIC: Checking GradCAM compatibility\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ensure model is ready\n",
    "model.eval()\n",
    "\n",
    "# Enable gradients on all parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Test different target layer configurations\n",
    "print(\"\\nTesting target layers...\")\n",
    "target_configs = [\n",
    "    (\"layer4 (entire)\", [model.layer4]),\n",
    "    (\"layer4[-1] (last block)\", [model.layer4[-1]]),\n",
    "    (\"layer4[1] (second block)\", [model.layer4[1]]),\n",
    "    (\"layer3[-1] (layer3 last)\", [model.layer3[-1]])\n",
    "]\n",
    "\n",
    "working_config = None\n",
    "\n",
    "for config_name, target_layers in target_configs:\n",
    "    try:\n",
    "        print(f\"\\nTrying: {config_name}\")\n",
    "        test_cam = GradCAM(model=model, target_layers=target_layers)\n",
    "        \n",
    "        # Get one test image\n",
    "        test_img, test_label = next(iter(DataLoader(test_dataset, batch_size=1)))\n",
    "        test_img = test_img.to(device)\n",
    "        \n",
    "        # Forward pass WITHOUT no_grad\n",
    "        test_output = model(test_img)\n",
    "        test_pred = test_output.argmax(1).item()\n",
    "        \n",
    "        # Generate heatmap\n",
    "        test_heatmap = test_cam(\n",
    "            input_tensor=test_img,\n",
    "            targets=[ClassifierOutputTarget(test_pred)]\n",
    "        )\n",
    "        \n",
    "        hm_min, hm_max, hm_mean = test_heatmap.min(), test_heatmap.max(), test_heatmap.mean()\n",
    "        print(f\"  Heatmap: min={hm_min:.4f}, max={hm_max:.4f}, mean={hm_mean:.4f}\")\n",
    "        \n",
    "        if hm_max > 0.01:\n",
    "            working_config = (config_name, target_layers)\n",
    "            print(f\"  ✓✓ SUCCESS! This configuration works!\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"  ✗ Still all zeros\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "\n",
    "if working_config is None:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CRITICAL ERROR: No working GradCAM configuration found!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nThis means your model has an architecture issue.\")\n",
    "    print(\"Please share:\")\n",
    "    print(\"1. How you created the model:\")\n",
    "    print(\"   Example: model = models.resnet18()\")\n",
    "    print(\"2. How you modified it:\")\n",
    "    print(\"   Example: model.fc = nn.Linear(512, 10)\")\n",
    "    print(\"3. How you loaded weights:\")\n",
    "    print(\"   Example: model.load_state_dict(torch.load(...))\")\n",
    "    \n",
    "    # Additional diagnostics\n",
    "    print(\"\\nModel structure check:\")\n",
    "    print(f\"  Has layer4: {hasattr(model, 'layer4')}\")\n",
    "    print(f\"  Layer4 type: {type(model.layer4) if hasattr(model, 'layer4') else 'N/A'}\")\n",
    "    \n",
    "    raise RuntimeError(\"Cannot generate GradCAM - see diagnostics above\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Using working configuration: {working_config[0]}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Now generate actual visualizations with the working config\n",
    "cam = GradCAM(model=model, target_layers=working_config[1])\n",
    "os.makedirs(f\"{CONFIG['artifacts_dir']}/gradcam\", exist_ok=True)\n",
    "\n",
    "gradcam_table = wandb.Table(columns=[\"GradCAM Overlay\", \"Original Image\", \"True Label\", \"Predicted\", \"Correct?\"])\n",
    "clean_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"\\nGenerating GradCAM visualizations...\")\n",
    "\n",
    "for idx, (img, label) in enumerate(clean_loader):\n",
    "    if idx >= CONFIG[\"num_gradcam\"]:\n",
    "        break\n",
    "    \n",
    "    # Prepare image for display\n",
    "    img_tensor = img[0].clone()  # (C, H, W)\n",
    "    img_unnorm = denormalize_image(img_tensor)  # Denormalized for visualization\n",
    "    img_np = img_unnorm.permute(1, 2, 0).cpu().numpy().astype(np.float32)\n",
    "    img_np = np.clip(img_np, 0, 1)  # Clip AFTER conversion\n",
    "    \n",
    "    pil_original = transforms.ToPILImage()(img_unnorm)\n",
    "    \n",
    "    # Run Grad-CAM - NO torch.no_grad() here!\n",
    "    input_tensor = img.to(device)\n",
    "    output = model(input_tensor)  # Allow gradients to flow\n",
    "    pred = output.argmax(1).item()\n",
    "    \n",
    "    # Generate heatmap\n",
    "    grayscale_cam = cam(\n",
    "        input_tensor=input_tensor,\n",
    "        targets=[ClassifierOutputTarget(pred)]\n",
    "    )\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    \n",
    "    if idx < 3:\n",
    "        print(f\"Sample {idx}: Heatmap min={grayscale_cam.min():.4f}, max={grayscale_cam.max():.4f}, mean={grayscale_cam.mean():.4f}\")\n",
    "        print(f\"  Predicted: {CLASSES[pred]}, True: {CLASSES[label.item()]}\")\n",
    "    \n",
    "    # Create overlay\n",
    "    visualization = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
    "    pil_overlay = Image.fromarray(visualization.astype(np.uint8))\n",
    "    \n",
    "    correct = \"Yes\" if pred == label.item() else \"No\"\n",
    "    \n",
    "    # Save\n",
    "    overlay_path = f\"{CONFIG['artifacts_dir']}/gradcam/overlay_{idx}.png\"\n",
    "    pil_overlay.save(overlay_path)\n",
    "    \n",
    "    gradcam_table.add_data(\n",
    "        wandb.Image(overlay_path),\n",
    "        wandb.Image(pil_original),\n",
    "        CLASSES[label.item()],\n",
    "        CLASSES[pred],\n",
    "        correct\n",
    "    )\n",
    "    \n",
    "    if (idx + 1) % 5 == 0:\n",
    "        print(f\"  Grad-CAM {idx+1}/{CONFIG['num_gradcam']} done\")\n",
    "\n",
    "wandb.log({\"Grad-CAM Gallery (20 examples)\": gradcam_table})\n",
    "print(\"✓ Grad-CAM complete — all heatmaps uploaded to W&B!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running adversarial noise check...\")\n",
    "noisy_correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        img = img.to(device)\n",
    "        noise = torch.randn_like(img) * CONFIG[\"noise_std\"]\n",
    "        noisy_img = torch.clamp(img + noise, 0, 1)\n",
    "        \n",
    "        with autocast(device_type):\n",
    "            pred = model(noisy_img).argmax(1)\n",
    "        \n",
    "        noisy_correct += (pred == label.to(device)).sum().item()\n",
    "        total += 1\n",
    "\n",
    "noisy_acc = noisy_correct / total\n",
    "wandb.log({f\"adversarial_noise_accuracy (σ={CONFIG['noise_std']})\": noisy_acc})\n",
    "print(f\"Noisy accuracy (σ={CONFIG['noise_std']}): {noisy_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing ECE (Expected Calibration Error)...\")\n",
    "\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        img = img.to(device)\n",
    "        with autocast(device_type):\n",
    "            logits = model(img)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(label)\n",
    "\n",
    "logits = torch.cat(all_logits)\n",
    "labels = torch.cat(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ccf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_metric = MulticlassCalibrationError(\n",
    "    num_classes=CONFIG[\"num_classes\"],\n",
    "    n_bins=CONFIG[\"ece_bins\"],\n",
    "    norm='l1'\n",
    ")\n",
    "ece_value = ece_metric(logits, labels).item()\n",
    "print(f\"✓ ECE (before calibration) = {ece_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bb8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(logits, dim=1)\n",
    "conf, pred = torch.max(probs, dim=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "bins = np.linspace(0, 1, CONFIG[\"ece_bins\"] + 1)\n",
    "accs = []\n",
    "confs_bin = []\n",
    "\n",
    "for i in range(CONFIG[\"ece_bins\"]):\n",
    "    mask = (conf >= bins[i]) & (conf < bins[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        accuracy = (pred[mask] == labels[mask]).float().mean().item()\n",
    "        confidence = conf[mask].mean().item()\n",
    "    else:\n",
    "        accuracy = 0\n",
    "        confidence = (bins[i] + bins[i+1]) / 2\n",
    "    accs.append(accuracy)\n",
    "    confs_bin.append(confidence)\n",
    "\n",
    "ax.bar(confs_bin, accs, width=0.06, alpha=0.8, color=\"skyblue\", edgecolor=\"black\")\n",
    "ax.plot([0, 1], [0, 1], \"--\", color=\"red\", linewidth=2, label=\"Perfect calibration\")\n",
    "ax.set_xlabel(\"Confidence\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(f\"Reliability Diagram – ECE = {ece_value:.4f}\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "wandb.log({\n",
    "    \"ECE\": ece_value,\n",
    "    \"Reliability Diagram\": wandb.Image(fig)\n",
    "})\n",
    "plt.close(fig)\n",
    "print(\"Reliability diagram saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying temperature scaling...\")\n",
    "\n",
    "T = nn.Parameter(torch.ones(1) * 1.5)\n",
    "optimizer = torch.optim.LBFGS([T], lr=0.01, max_iter=1000)\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    loss = F.cross_entropy(logits / T, labels)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "optimizer.step(closure)\n",
    "print(f\"Learned temperature: {T.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46afe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_logits = logits / T.item()\n",
    "ece_metric_scaled = MulticlassCalibrationError(\n",
    "    num_classes=CONFIG[\"num_classes\"],\n",
    "    n_bins=CONFIG[\"ece_bins\"],\n",
    "    norm='l1'\n",
    ")\n",
    "ece_scaled = ece_metric_scaled(scaled_logits, labels).item()\n",
    "\n",
    "wandb.log({\n",
    "    \"temperature_scaling_T\": T.item(),\n",
    "    \"ECE_after_temperature_scaling\": ece_scaled\n",
    "})\n",
    "\n",
    "print(f\"ECE before: {ece_value:.4f} → after T-scaling: {ece_scaled:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating confusion matrix...\")\n",
    "\n",
    "y_true = labels.cpu().numpy()\n",
    "y_pred = pred.cpu().numpy()\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=CLASSES,\n",
    "    yticklabels=CLASSES,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.xlabel(\"Predicted\", fontsize=14)\n",
    "plt.ylabel(\"True\", fontsize=14)\n",
    "plt.title(\"Confusion Matrix – CIFAR-10 Test Set\", fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "wandb.log({\"Confusion Matrix\": wandb.Image(plt)})\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Confusion matrix uploaded to W&B!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde12720",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total test images: {len(test_dataset)}\")\n",
    "print(f\"Misclassified examples found: {len(misclassified)}\")\n",
    "print(f\"Grad-CAM visualizations: {CONFIG['num_gradcam']}\")\n",
    "print(f\"Adversarial noise accuracy (σ={CONFIG['noise_std']}): {noisy_acc:.4f}\")\n",
    "print(f\"ECE (before calibration): {ece_value:.4f}\")\n",
    "print(f\"Temperature learned: {T.item():.3f}\")\n",
    "print(f\"ECE (after calibration): {ece_scaled:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Finish W&B logging\n",
    "wandb.finish()\n",
    "print(\"\\n✓ All diagnostics complete! W&B run finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b22197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
