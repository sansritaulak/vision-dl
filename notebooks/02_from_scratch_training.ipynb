{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e5029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import wandb\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72567905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root():\n",
    "    cur = os.path.abspath(os.curdir)\n",
    "    while os.path.basename(cur) != \"cifar-week3\":\n",
    "        parent = os.path.dirname(cur)\n",
    "        if parent == cur:\n",
    "            raise RuntimeError(\"Folder must be named 'cifar-week3'\")\n",
    "        cur = parent\n",
    "    return cur\n",
    "\n",
    "ROOT = find_root()\n",
    "DATA_DIR = os.path.join(ROOT, \"data\")\n",
    "ARTIFACTS_DIR = os.path.join(ROOT, \"artifacts\")\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c5f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce21bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33musansrita\u001b[0m (\u001b[33musansrita-kathmandu-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce79202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\cifar-week3\\notebooks\\wandb\\run-20251204_183424-wazwujw1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/wazwujw1' target=\"_blank\">cnn9-amp-onecycle</a></strong> to <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/wazwujw1' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/wazwujw1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/wazwujw1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1a79959f620>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"cifar10-week3\",\n",
    "    group=\"Day2-FromScratch-CNN\",\n",
    "    name=\"cnn9-amp-onecycle\",\n",
    "    config={\n",
    "        \"model\": \"CNN9 (from scratch)\",\n",
    "        \"epochs\": 50,\n",
    "        \"batch_size\": 128,\n",
    "        \"optimizer\": \"SGD + OneCycleLR\",\n",
    "        \"lr_max\": 0.1,\n",
    "        \"weight_decay\": 5e-4,\n",
    "        \"amp\": True,\n",
    "        \"augmentation\": \"basic + RandAugment\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096a9a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD5 checksums:\n",
      "  c:\\cifar-week3\\data\\cifar-10-batches-py\\data_batch_1: c99cafc152244af753f735de768cd75f\n",
      "  c:\\cifar-week3\\data\\cifar-10-batches-py\\test_batch: 40351d587109b95175f43aff81a1287e\n"
     ]
    }
   ],
   "source": [
    "def md5(p): \n",
    "    if not os.path.exists(p): return \"MISSING\"\n",
    "    h = hashlib.md5()\n",
    "    with open(p, \"rb\") as f:\n",
    "        for c in iter(lambda: f.read(4096), b\"\"): h.update(c)\n",
    "    return h.hexdigest()\n",
    "\n",
    "print(\"MD5 checksums:\")\n",
    "for f in [\"data_batch_1\", \"test_batch\"]:\n",
    "    p = os.path.join(DATA_DIR, \"cifar-10-batches-py\", f)\n",
    "    print(f\"  {p}: {md5(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca7b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.4914, 0.4822, 0.4465]\n",
    "STD  = [0.2470, 0.2430, 0.2610]\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "full_train = datasets.CIFAR10(root=DATA_DIR, train=True,  download=True, transform=train_tf)\n",
    "test_ds    = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=test_tf)\n",
    "\n",
    "train_ds, val_ds = random_split(full_train, [45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08e166fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandera.pandas as pa\n",
    "    labels = [int(train_ds[i][1]) for i in range(500)]\n",
    "    pa.DataFrameSchema({\"label\": pa.Column(int, pa.Check(lambda s: s.between(0,9).all()))})(pd.DataFrame({\"label\": labels}))\n",
    "    print(\"Pandera validation PASSED\")\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1dd8411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 4,065,098\n"
     ]
    }
   ],
   "source": [
    "class CNN9(nn.Module):\n",
    "    def conv(self, i, o): \n",
    "        return nn.Sequential(nn.Conv2d(i,o,3,1,1,bias=False), nn.BatchNorm2d(o), nn.ReLU(inplace=True))\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self.conv(3,64),   self.conv(64,128),   nn.MaxPool2d(2),\n",
    "            self.conv(128,128), self.conv(128,256),  nn.MaxPool2d(2),\n",
    "            self.conv(256,512), self.conv(512,512),  nn.MaxPool2d(2),\n",
    "            nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Linear(512,10)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "model = CNN9().to(device)\n",
    "print(f\"Params: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64c19fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "404add5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = 50 * len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cdc0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.1,\n",
    "    total_steps=total_steps, \n",
    "    pct_start=0.2,\n",
    "    anneal_strategy='cos',\n",
    "    cycle_momentum=True,\n",
    "    base_momentum=0.85,\n",
    "    max_momentum=0.95,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a4314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.amp.GradScaler('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afccb250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 → Val: 0.4952 (Best: 0.4952)\n",
      "Epoch 02 → Val: 0.4178 (Best: 0.4952)\n",
      "Epoch 03 → Val: 0.5954 (Best: 0.5954)\n",
      "Epoch 04 → Val: 0.6270 (Best: 0.6270)\n",
      "Epoch 05 → Val: 0.6950 (Best: 0.6950)\n",
      "Epoch 06 → Val: 0.6280 (Best: 0.6950)\n",
      "Epoch 07 → Val: 0.6672 (Best: 0.6950)\n",
      "Epoch 08 → Val: 0.6866 (Best: 0.6950)\n",
      "Epoch 09 → Val: 0.7024 (Best: 0.7024)\n",
      "Epoch 10 → Val: 0.7442 (Best: 0.7442)\n",
      "Epoch 11 → Val: 0.7852 (Best: 0.7852)\n",
      "Epoch 12 → Val: 0.6918 (Best: 0.7852)\n",
      "Epoch 13 → Val: 0.7194 (Best: 0.7852)\n",
      "Epoch 14 → Val: 0.7318 (Best: 0.7852)\n",
      "Epoch 15 → Val: 0.7836 (Best: 0.7852)\n",
      "Epoch 16 → Val: 0.7690 (Best: 0.7852)\n",
      "Epoch 17 → Val: 0.7392 (Best: 0.7852)\n",
      "Epoch 18 → Val: 0.7496 (Best: 0.7852)\n",
      "Epoch 19 → Val: 0.7514 (Best: 0.7852)\n",
      "Epoch 20 → Val: 0.7964 (Best: 0.7964)\n",
      "Epoch 21 → Val: 0.8066 (Best: 0.8066)\n",
      "Epoch 22 → Val: 0.7730 (Best: 0.8066)\n",
      "Epoch 23 → Val: 0.7550 (Best: 0.8066)\n",
      "Epoch 24 → Val: 0.7870 (Best: 0.8066)\n",
      "Epoch 25 → Val: 0.7624 (Best: 0.8066)\n",
      "Epoch 26 → Val: 0.8334 (Best: 0.8334)\n",
      "Epoch 27 → Val: 0.7442 (Best: 0.8334)\n",
      "Epoch 28 → Val: 0.7976 (Best: 0.8334)\n",
      "Epoch 29 → Val: 0.8024 (Best: 0.8334)\n",
      "Epoch 30 → Val: 0.8264 (Best: 0.8334)\n",
      "Epoch 31 → Val: 0.8304 (Best: 0.8334)\n",
      "Epoch 32 → Val: 0.7932 (Best: 0.8334)\n",
      "Epoch 33 → Val: 0.8286 (Best: 0.8334)\n",
      "Epoch 34 → Val: 0.8424 (Best: 0.8424)\n",
      "Epoch 35 → Val: 0.7744 (Best: 0.8424)\n",
      "Epoch 36 → Val: 0.8488 (Best: 0.8488)\n",
      "Epoch 37 → Val: 0.8388 (Best: 0.8488)\n",
      "Epoch 38 → Val: 0.8538 (Best: 0.8538)\n",
      "Epoch 39 → Val: 0.8586 (Best: 0.8586)\n",
      "Epoch 40 → Val: 0.8666 (Best: 0.8666)\n",
      "Epoch 41 → Val: 0.8558 (Best: 0.8666)\n",
      "Epoch 42 → Val: 0.8802 (Best: 0.8802)\n",
      "Epoch 43 → Val: 0.8860 (Best: 0.8860)\n",
      "Epoch 44 → Val: 0.8880 (Best: 0.8880)\n",
      "Epoch 45 → Val: 0.9064 (Best: 0.9064)\n",
      "Epoch 46 → Val: 0.9048 (Best: 0.9064)\n",
      "Epoch 47 → Val: 0.9058 (Best: 0.9064)\n",
      "Epoch 48 → Val: 0.9112 (Best: 0.9112)\n",
      "Epoch 49 → Val: 0.9092 (Best: 0.9112)\n",
      "Epoch 50 → Val: 0.9078 (Best: 0.9112)\n"
     ]
    }
   ],
   "source": [
    "best_val = 0.0\n",
    "global_step = 0  \n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            loss = criterion(model(x), y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if global_step < total_steps:\n",
    "            scheduler.step()\n",
    "        global_step += 1\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                correct += (model(x).argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    wandb.log({\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "        \"epoch\": epoch\n",
    "    })\n",
    "\n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} → Val: {val_acc:.4f} (Best: {best_val:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "204e03ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL TEST ACCURACY: 0.9349\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        correct += (model(x).argmax(1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "test_acc = correct / total\n",
    "\n",
    "wandb.log({\"test_accuracy_final\": test_acc, \"best_val_accuracy\": best_val})\n",
    "print(f\"\\nFINAL TEST ACCURACY: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0180ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▁▃▄▅▆▇███████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>test_accuracy_final</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▂▁▄▄▅▅▅▆▆▅▅▆▆▆▆▆▇▆▆▆▇▆▆▆▇▆▇▇▆▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>0.9112</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>test_accuracy_final</td><td>0.9349</td></tr><tr><td>val_accuracy</td><td>0.9078</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cnn9-amp-onecycle</strong> at: <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/wazwujw1' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/wazwujw1</a><br> View project at: <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3</a><br>Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251204_183424-wazwujw1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = os.path.join(ARTIFACTS_DIR, \"day2_cnn9_final.pth\")\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "artifact = wandb.Artifact(\"day2-cnn9-model\", type=\"model\")\n",
    "artifact.add_file(path)\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
