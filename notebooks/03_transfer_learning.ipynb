{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37c5383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\cifar-week3\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import timm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66029c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root():\n",
    "    cur = os.path.abspath(os.curdir)\n",
    "    while os.path.basename(cur) != \"cifar-week3\":\n",
    "        parent = os.path.dirname(cur)\n",
    "        if parent == cur:\n",
    "            raise RuntimeError(\"Rename your main folder to 'cifar-week3'\")\n",
    "        cur = parent\n",
    "    return cur\n",
    "\n",
    "ROOT = find_root()\n",
    "DATA_DIR = os.path.join(ROOT, \"data\")\n",
    "ARTIFACTS_DIR = os.path.join(ROOT, \"artifacts\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9856f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device → cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device → {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d62729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.4914, 0.4822, 0.4465]\n",
    "STD  = [0.2470, 0.2430, 0.2610]\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "full_train = datasets.CIFAR10(root=DATA_DIR, train=True,  download=True, transform=train_tf)\n",
    "test_ds    = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=test_tf)\n",
    "train_ds, val_ds = random_split(full_train, [45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32053635",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    {\"name\": \"resnet18-frozen\",         \"unfreeze_layers\": []},\n",
    "    {\"name\": \"resnet18-partial-unfreeze\", \"unfreeze_layers\": [\"layer4\"]},\n",
    "    {\"name\": \"resnet18-full-unfreeze\",  \"unfreeze_layers\": [\"layer1\",\"layer2\",\"layer3\",\"layer4\"]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57ab2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_resnet18(cfg):\n",
    "    wandb.init(\n",
    "        project=\"cifar10-week3\",\n",
    "        group=\"Day3-Transfer-Learning\",\n",
    "        name=cfg[\"name\"],\n",
    "        config={\"model\": \"resnet18\", \"unfreeze\": cfg[\"unfreeze_layers\"], \"epochs\": 25}\n",
    "    )\n",
    "\n",
    "    model = timm.create_model(\"resnet18\", pretrained=True, num_classes=10).to(device)\n",
    "\n",
    "    # === FREEZE / UNFREEZE LOGIC ===\n",
    "    # Freeze everything first\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Always train classifier\n",
    "    for param in model.get_classifier().parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Unfreeze requested layers\n",
    "    for layer_name in cfg[\"unfreeze_layers\"]:\n",
    "        for param in getattr(model, layer_name).parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Print what is trainable\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total     = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trainable params: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4, weight_decay=0.05)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    best_val = 0.0\n",
    "    for epoch in range(1, 26):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss = criterion(model(x), y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Val\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                correct += (model(x).argmax(1) == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        val_acc = correct / total\n",
    "        wandb.log({\"val_accuracy\": val_acc, \"epoch\": epoch})\n",
    "        if val_acc > best_val: best_val = val_acc\n",
    "        print(f\"Epoch {epoch:02d} → Val: {val_acc:.4f} (best {best_val:.4f})\")\n",
    "\n",
    "    # Test\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            correct += (model(x).argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    test_acc = correct / total\n",
    "    wandb.log({\"test_accuracy_final\": test_acc, \"best_val_accuracy\": best_val})\n",
    "    print(f\"\\n{cfg['name']} → TEST ACCURACY: {test_acc:.4f}\\n\")\n",
    "\n",
    "    # Save + upload .pth\n",
    "    path = os.path.join(ARTIFACTS_DIR, f\"day3_{cfg['name']}.pth\")\n",
    "    torch.save(model.state_dict(), path)\n",
    "    artifact = wandb.Artifact(f\"day3-{cfg['name']}\", type=\"model\")\n",
    "    artifact.add_file(path)\n",
    "    wandb.log_artifact(artifact)\n",
    "    print(f\"Uploaded → {path}\")\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4947eaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33musansrita\u001b[0m (\u001b[33musansrita-kathmandu-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\cifar-week3\\notebooks\\wandb\\run-20251204_145024-78s28me5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/78s28me5' target=\"_blank\">resnet18-frozen</a></strong> to <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/78s28me5' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/78s28me5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\cifar-week3\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:121: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\usans\\.cache\\huggingface\\hub\\models--timm--resnet18.a1_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\usans\\AppData\\Local\\Temp\\ipykernel_35612\\2188206624.py:33: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 5,130 / 11,181,642 (0.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usans\\AppData\\Local\\Temp\\ipykernel_35612\\2188206624.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 → Val: 0.4148 (best 0.4148)\n",
      "Epoch 02 → Val: 0.4554 (best 0.4554)\n",
      "Epoch 03 → Val: 0.4678 (best 0.4678)\n",
      "Epoch 04 → Val: 0.4786 (best 0.4786)\n",
      "Epoch 05 → Val: 0.5054 (best 0.5054)\n",
      "Epoch 06 → Val: 0.4968 (best 0.5054)\n",
      "Epoch 07 → Val: 0.4996 (best 0.5054)\n",
      "Epoch 08 → Val: 0.5018 (best 0.5054)\n",
      "Epoch 09 → Val: 0.5124 (best 0.5124)\n",
      "Epoch 10 → Val: 0.4990 (best 0.5124)\n",
      "Epoch 11 → Val: 0.5210 (best 0.5210)\n",
      "Epoch 12 → Val: 0.5114 (best 0.5210)\n",
      "Epoch 13 → Val: 0.5092 (best 0.5210)\n",
      "Epoch 14 → Val: 0.5100 (best 0.5210)\n",
      "Epoch 15 → Val: 0.5036 (best 0.5210)\n",
      "Epoch 16 → Val: 0.5106 (best 0.5210)\n",
      "Epoch 17 → Val: 0.5308 (best 0.5308)\n",
      "Epoch 18 → Val: 0.5060 (best 0.5308)\n",
      "Epoch 19 → Val: 0.5064 (best 0.5308)\n",
      "Epoch 20 → Val: 0.5186 (best 0.5308)\n",
      "Epoch 21 → Val: 0.5232 (best 0.5308)\n",
      "Epoch 22 → Val: 0.5078 (best 0.5308)\n",
      "Epoch 23 → Val: 0.5196 (best 0.5308)\n",
      "Epoch 24 → Val: 0.5162 (best 0.5308)\n",
      "Epoch 25 → Val: 0.5190 (best 0.5308)\n",
      "\n",
      "resnet18-frozen → TEST ACCURACY: 0.7193\n",
      "\n",
      "Uploaded → c:\\cifar-week3\\artifacts\\day3_resnet18-frozen.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>test_accuracy_final</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▅▆▆▆▆▇▆▇▇▇▇▆▇█▇▇▇█▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>0.5308</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>test_accuracy_final</td><td>0.7193</td></tr><tr><td>val_accuracy</td><td>0.519</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18-frozen</strong> at: <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/78s28me5' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/78s28me5</a><br> View project at: <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3</a><br>Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251204_145024-78s28me5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\cifar-week3\\notebooks\\wandb\\run-20251204_153713-1wqsyoh1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/1wqsyoh1' target=\"_blank\">resnet18-partial-unfreeze</a></strong> to <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/1wqsyoh1' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/1wqsyoh1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 8,398,858 / 11,181,642 (75.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usans\\AppData\\Local\\Temp\\ipykernel_35612\\2188206624.py:33: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\usans\\AppData\\Local\\Temp\\ipykernel_35612\\2188206624.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 → Val: 0.5988 (best 0.5988)\n",
      "Epoch 02 → Val: 0.6368 (best 0.6368)\n",
      "Epoch 03 → Val: 0.6558 (best 0.6558)\n",
      "Epoch 04 → Val: 0.6726 (best 0.6726)\n",
      "Epoch 05 → Val: 0.6792 (best 0.6792)\n",
      "Epoch 06 → Val: 0.6878 (best 0.6878)\n",
      "Epoch 07 → Val: 0.6826 (best 0.6878)\n",
      "Epoch 08 → Val: 0.6928 (best 0.6928)\n",
      "Epoch 09 → Val: 0.6972 (best 0.6972)\n",
      "Epoch 10 → Val: 0.6972 (best 0.6972)\n",
      "Epoch 11 → Val: 0.7090 (best 0.7090)\n",
      "Epoch 12 → Val: 0.7086 (best 0.7090)\n",
      "Epoch 13 → Val: 0.7108 (best 0.7108)\n",
      "Epoch 14 → Val: 0.7116 (best 0.7116)\n",
      "Epoch 15 → Val: 0.7150 (best 0.7150)\n",
      "Epoch 16 → Val: 0.7252 (best 0.7252)\n",
      "Epoch 17 → Val: 0.7180 (best 0.7252)\n",
      "Epoch 18 → Val: 0.7192 (best 0.7252)\n",
      "Epoch 19 → Val: 0.7192 (best 0.7252)\n",
      "Epoch 20 → Val: 0.7240 (best 0.7252)\n",
      "Epoch 21 → Val: 0.7158 (best 0.7252)\n",
      "Epoch 22 → Val: 0.7190 (best 0.7252)\n",
      "Epoch 23 → Val: 0.7122 (best 0.7252)\n",
      "Epoch 24 → Val: 0.7142 (best 0.7252)\n",
      "Epoch 25 → Val: 0.7190 (best 0.7252)\n",
      "\n",
      "resnet18-partial-unfreeze → TEST ACCURACY: 0.9052\n",
      "\n",
      "Uploaded → c:\\cifar-week3\\artifacts\\day3_resnet18-partial-unfreeze.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>test_accuracy_final</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇█████▇█▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>0.7252</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>test_accuracy_final</td><td>0.9052</td></tr><tr><td>val_accuracy</td><td>0.719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18-partial-unfreeze</strong> at: <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/1wqsyoh1' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/1wqsyoh1</a><br> View project at: <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3</a><br>Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251204_153713-1wqsyoh1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\cifar-week3\\notebooks\\wandb\\run-20251204_162146-vtvr3pns</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/vtvr3pns' target=\"_blank\">resnet18-full-unfreeze</a></strong> to <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/vtvr3pns' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/vtvr3pns</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 11,172,106 / 11,181,642 (99.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usans\\AppData\\Local\\Temp\\ipykernel_35612\\2188206624.py:33: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\usans\\AppData\\Local\\Temp\\ipykernel_35612\\2188206624.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 → Val: 0.7160 (best 0.7160)\n",
      "Epoch 02 → Val: 0.7526 (best 0.7526)\n",
      "Epoch 03 → Val: 0.7676 (best 0.7676)\n",
      "Epoch 04 → Val: 0.7872 (best 0.7872)\n",
      "Epoch 05 → Val: 0.7940 (best 0.7940)\n",
      "Epoch 06 → Val: 0.8060 (best 0.8060)\n",
      "Epoch 07 → Val: 0.7962 (best 0.8060)\n",
      "Epoch 08 → Val: 0.8000 (best 0.8060)\n",
      "Epoch 09 → Val: 0.8148 (best 0.8148)\n",
      "Epoch 10 → Val: 0.8104 (best 0.8148)\n",
      "Epoch 11 → Val: 0.8220 (best 0.8220)\n",
      "Epoch 12 → Val: 0.8292 (best 0.8292)\n",
      "Epoch 13 → Val: 0.8274 (best 0.8292)\n",
      "Epoch 14 → Val: 0.8252 (best 0.8292)\n",
      "Epoch 15 → Val: 0.8250 (best 0.8292)\n",
      "Epoch 16 → Val: 0.8252 (best 0.8292)\n",
      "Epoch 17 → Val: 0.8340 (best 0.8340)\n",
      "Epoch 18 → Val: 0.8408 (best 0.8408)\n",
      "Epoch 19 → Val: 0.8344 (best 0.8408)\n",
      "Epoch 20 → Val: 0.8294 (best 0.8408)\n",
      "Epoch 21 → Val: 0.8392 (best 0.8408)\n",
      "Epoch 22 → Val: 0.8302 (best 0.8408)\n",
      "Epoch 23 → Val: 0.8440 (best 0.8440)\n",
      "Epoch 24 → Val: 0.8406 (best 0.8440)\n",
      "Epoch 25 → Val: 0.8338 (best 0.8440)\n",
      "\n",
      "resnet18-full-unfreeze → TEST ACCURACY: 0.9542\n",
      "\n",
      "Uploaded → c:\\cifar-week3\\artifacts\\day3_resnet18-full-unfreeze.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>test_accuracy_final</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▅▅▆▅▆▆▆▇▇▇▇▇▇▇█▇▇█▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>0.844</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>test_accuracy_final</td><td>0.9542</td></tr><tr><td>val_accuracy</td><td>0.8338</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18-full-unfreeze</strong> at: <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/vtvr3pns' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3/runs/vtvr3pns</a><br> View project at: <a href='https://wandb.ai/usansrita-kathmandu-university/cifar10-week3' target=\"_blank\">https://wandb.ai/usansrita-kathmandu-university/cifar10-week3</a><br>Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251204_162146-vtvr3pns\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for exp in experiments:\n",
    "    run_resnet18(exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
